{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ss2rKoGH4Jy6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bkg_CwCQGy4L"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDWcYoPc60JP"
      },
      "source": [
        "# 2CS SIQ2-SIL2 TP02. Régression logistique Multi-classes\n",
        "\n",
        "Dans ce TP, nous allons généraliser la réression linéaire binaire afin de traiter le cas de multiples classes.\n",
        "Ensuite, dans la partie analyse, nous allons voir quelques méthodes pour traiter le classement multi-classes (cas d'étude, régression logistique)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhGdBSze60JS"
      },
      "source": [
        "- **Binôme** **01** : BAZIZ meriem \n",
        "- **Binôme** **02** :BOUCETTA Anfal Yousra\n",
        "- **Groupe** : SIL2"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C1gbTw_Z3x_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV57O0eM60JT",
        "outputId": "bf891629-6717-4975-c754-2e9785f76e14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.22.4', '1.4.4', '3.7.1')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy             as np\n",
        "import pandas            as pd \n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "\n",
        "np.__version__, pd.__version__, matplotlib.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkqHgMOj60JV"
      },
      "outputs": [],
      "source": [
        "from typing          import Tuple, List, Type\n",
        "from collections.abc import Callable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE7wBVR660JW"
      },
      "source": [
        "**INTRODUCTION**\n",
        "\n",
        "Nous avons implémenté le cas d'une seule classe (binaire : oui ou non). \n",
        "Pour appliquer un classement sur plusieurs classes, nous pouvons entraîner $L$ modèles de régression logistique (où $L$ est le nombre des classes). \n",
        "Dans ce cas, nos résultats (Y) doivent encodée en 0 et 1. \n",
        "Pour un modèle $M_i$ d'une classe $C_i$, la sortie $Y$ doit avoir 1 si $C_i$, 0 si une autre classe. \n",
        "Cette architecture est appelée : One-to-rest classification.\n",
        "\n",
        "Une autre approche (celle que nous allons implémenter) est d'encoder la sortie en utilisant OneHot encoder. \n",
        "Pour $L$ classes et un échantillon donnée, nous allons avoir $L$ sorties (une ayant 1 et les autres 0). \n",
        "Pour un dataset avec $M$ échantillons, $N$ caractéristiques et $L$ classes, nous allons avoir les dimensions suivantes : \n",
        "- $X [M, N]$\n",
        "- $Y [M, L]$\n",
        "- $\\theta [N, L]$\n",
        "\n",
        "Cette dernière approche s'appelle maximum entropy (MaxEnt). \n",
        "C'est une généralisation de la régresion logistique binaire.\n",
        "\n",
        "\n",
        "## I. Réalisation des algorithmes\n",
        "\n",
        "Cette partie sert à améliorer la compréhension des algorithmes d'apprentissage automatique vus en cours en les implémentant à partir de zéro. \n",
        "Pour ce faire, nous allons utiliser la bibliothèque **numpy** qui est utile dans les calcules surtout matricielles.\n",
        "\n",
        "### I.1. Combinaison linéaire\n",
        "\n",
        "Les $N$  caractéristiques sont combinées linéairement comme dans la régression linéaire binaire. \n",
        "La seule différence est que nous avons plus de classes, donc le nombre des paramètres va être multiplié par le nombre des classes.\n",
        "La somme pondérée d'une classe $c$ est calculée selon la formule : \n",
        "\n",
        "$$Z_c = zfn_c(X, \\theta) = \\sum\\limits_{j=0}^{N} \\theta_{(c, j)} X_j | X_0 = 1 $$\n",
        "\n",
        "La forme matricielle de $Z$ sera : \n",
        "$$Z = zfn(X, \\theta) = X \\cdot \\theta$$\n",
        "\n",
        "- $X[M, N]$      : une matrice de M lignes (échantillons) et N colonnes (caractéristiques, y compris le biais).  \n",
        "- $\\theta[N, L]$ : une matrice de N lignes (caractéristiques, y compris le biais) et L colonnes (classes). \n",
        "- $Z[M, L]$      : une matrice de M lignes (échantillons) et L colonnes (classes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m53nx_960JX",
        "outputId": "d685b58e-2c08-4c3e-c0b6-5db706acd775"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0. , 0. , 0. ],\n",
              "       [0.5, 0.1, 0.6],\n",
              "       [0.2, 0.3, 0. ],\n",
              "       [0.7, 0.4, 0.6]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# TODO: Combinaison linéaire \n",
        "def zfn(X: np.ndarray, Theta: np.ndarray) -> np.ndarray: \n",
        "    return X@Theta\n",
        "\n",
        "#=====================================================================\n",
        "# TEST UNITAIRE\n",
        "#=====================================================================\n",
        "# Resultat : \n",
        "# array([[0. , 0. , 0. ],\n",
        "#        [0.5, 0.1, 0.6],\n",
        "#        [0.2, 0.3, 0. ],\n",
        "#        [0.7, 0.4, 0.6]])\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "X_tn = np.array([[0., 0.], \n",
        "                 [1., 0.], \n",
        "                 [0., 1.], \n",
        "                 [1., 1.]]) # 4 échntillons, 2 caractéristiques\n",
        "Theta_tn = np.array([[0.5, 0.1, 0.6],\n",
        "                     [0.2, 0.3, 0.0]]) # 2 caractéristiques, 3 classes \n",
        "\n",
        "zfn(X_tn, Theta_tn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0kjbIyd60JY"
      },
      "source": [
        "### I.2. Calcul des probabilités\n",
        "\n",
        "Les valeurs combinées sont transformées à des probabilités en utilisant la fonction softmax. \n",
        "La fonction softmax nous assure que la somme des probabilités des classes soit égale à 1.\n",
        "Cette fonction prend les combinaisons linéaires $Z[M, L]$ et calcule les probabilités $P[M, L]$ comme suite : \n",
        "\n",
        "$$softmax(Z)=\\frac{e^Z}{\\sum\\limits_{k=1}^{L} e^{Z_k}}$$\n",
        "\n",
        "- $M$ : nombre des échantillons\n",
        "- $N$ : nombre des caractéristiques\n",
        "- $L$ : nombre des classes\n",
        "- La somme des probabilités de chaque ligne doit être 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKZ-SLfw60JZ",
        "outputId": "d232706f-6c05-4225-b8a3-0de8ac39509e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.33333333, 0.33333333, 0.33333333],\n",
              "       [0.36029662, 0.24151404, 0.39818934],\n",
              "       [0.34200877, 0.37797814, 0.28001309],\n",
              "       [0.37797814, 0.28001309, 0.34200877]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# TODO: Softmax\n",
        "def softmax(Z: np.ndarray) -> np.ndarray:\n",
        "    exp_Z = np.exp(Z)\n",
        "    softmax = exp_Z / np.tile(np.sum(exp_Z,axis=1),(Z.shape[1],1)).T\n",
        "    return softmax\n",
        "\n",
        "#=====================================================================\n",
        "# TEST UNITAIRE\n",
        "#=====================================================================\n",
        "# Resultat : \n",
        "# array([[0.33333333, 0.33333333, 0.33333333],\n",
        "#       [0.36029662, 0.24151404, 0.39818934],\n",
        "#       [0.34200877, 0.37797814, 0.28001309],\n",
        "#       [0.37797814, 0.28001309, 0.34200877]])\n",
        "#---------------------------------------------------------------------\n",
        "Z_tn = np.array([[0. , 0. , 0. ],\n",
        "                 [0.5, 0.1, 0.6],\n",
        "                 [0.2, 0.3, 0. ],\n",
        "                 [0.7, 0.4, 0.6]])\n",
        "softmax(Z_tn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbgLjdP060JZ"
      },
      "source": [
        "### I.3. Prédiction \n",
        "\n",
        "Etant donnée les probabilités des classes pour chaque échantillon, nous devons choisir la classe avec le max de probabilité.\n",
        "\n",
        "$$\n",
        "\\hat{C}^{(i)}_j = \n",
        "\\begin{cases}\n",
        "1 & si & H^{(i)}_j \\ge \\max P^{(i)}\\\\\n",
        "0 & sinon & \\\\\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "- $H[M, L]$ probabilités où chaque ligne est un échantillon et chaque colonne est une classe\n",
        "- $\\hat{C}[M, L]$ prédictions où chaque ligne est un échantillon et chaque colonne est une classe. $\\hat{C}^{(i)}_j \\in \\{0, 1\\}$\n",
        "\n",
        "Lorsqu'il y a deux colonnes ou plus ayant le même max, nous prenons la première."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVU0lScw60Ja",
        "outputId": "fdfdf13d-d212-495b-d724-537144edfed3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# TODO: Prédictions multiclasses\n",
        "def cn(H: np.ndarray) -> np.ndarray:\n",
        "    # Get the index of the maximum value in each row of H\n",
        "    max_index = np.argmax(H, axis=1)\n",
        "    C = np.zeros_like(H)\n",
        "    C[np.arange(H.shape[0]), max_index] = 1\n",
        "    \n",
        "    return C\n",
        "#=====================================================================\n",
        "# TEST UNITAIRE\n",
        "#=====================================================================\n",
        "# Resultat : \n",
        "# array([[1, 0, 0],\n",
        "#        [0, 0, 1],\n",
        "#        [0, 1, 0],\n",
        "#        [1, 0, 0]])\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "H_tn = np.array([[0.33333333, 0.33333333, 0.33333333],\n",
        "             [0.36029662, 0.24151404, 0.39818934],\n",
        "             [0.34200877, 0.37797814, 0.28001309],\n",
        "             [0.37797814, 0.28001309, 0.34200877]])\n",
        "cn(H_tn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HxY2TdA60Jb"
      },
      "source": [
        "### I.4. Calcul du coût \n",
        "\n",
        "Nous référons aux probabilités calculées par la fonction softmax comme $H$, où $H_c$ est la probabilité d'une classe $c$.\n",
        "Etant donné un échantillon $X^{(i)}$, son coût est calculé comme : \n",
        "\n",
        "$$ cout(H^{(i)}, Y^{(i)}) = - \\sum\\limits_{c=1}^{L} Y^{(i)}_c \\log(H^{(i)}_c)$$\n",
        "\n",
        "Le coût total est la moyenne des coût de tous les échantillons\n",
        "\n",
        "$$J(H, Y) = \\frac{1}{M} \\sum\\limits_{i=1}^{M} cout(H^{(i)}, Y^{(i)})$$\n",
        "\n",
        "- $H[M, L]$ : les probabilités estimées de chaque échantillon (M) de chaque classe (L)\n",
        "- $Y[M, L]$ : les probabilités réelles (1 ou 0) de chaque échantillon (M) de chaque classe (L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U-lEFgj60Jb",
        "outputId": "552ef010-b450-490c-e96d-6e161da4b8ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.1913194530574498"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# TODO: Coût du classement multiclasses \n",
        "def jn(H: np.ndarray, Y: np.ndarray) -> np.ndarray:\n",
        "    M = Y.shape[0]\n",
        "    cout = -np.sum(Y*np.log(H))\n",
        "    return 1/M*np.sum(cout)\n",
        "\n",
        "#=====================================================================\n",
        "# TEST UNITAIRE\n",
        "#=====================================================================\n",
        "# Resultat : 1.1913194530574498\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "H_tn = np.array([[0.33333333, 0.33333333, 0.33333333],\n",
        "                 [0.36029662, 0.24151404, 0.39818934],\n",
        "                 [0.34200877, 0.37797814, 0.28001309],\n",
        "                 [0.37797814, 0.28001309, 0.34200877]])\n",
        "Y_tn = np.array([[1,0,0], [0,1,0], [0,0,1], [1,0,0]])\n",
        "\n",
        "jn(H_tn, Y_tn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_483lhGF60Jc"
      },
      "source": [
        "### I.5. Calcul des gradients\n",
        "\n",
        "La taille des gradients est la même que celle des paramètres $\\theta[N, L]$. \n",
        "\n",
        "$$\\frac{\\partial J}{\\theta_j} = \\frac{1}{M} \\sum\\limits_{i=1}^{M} (H^{(i)} - Y^{(i)}) X^{(i)}_{j} $$\n",
        "\n",
        "Sa forme matricielle sera \n",
        "$$\\frac{\\partial J}{\\theta_j} = \\frac{1}{M} X^\\top \\cdot (H-Y) $$\n",
        "\n",
        "- $X[M, N]$ : une matrice de M lignes (échantillons) et N colonnes (caractéristiques, y compris le biais).  \n",
        "- $H[M, L]$ : les probabilités estimées de chaque échantillon (M) de chaque classe (L)\n",
        "- $Y[M, L]$ : les probabilités réelles (1 ou 0) de chaque échantillon (M) de chaque classe (L)\n",
        "- $\\frac{\\partial J}{\\theta}[N, L]$ : une matrice de L lignes (classes) et N colonnes (caractéristiques, y compris le biais). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJhLrZCY60Jc",
        "outputId": "b7073b53-6469-4d12-cc56-0b42558b98f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.06543131, -0.11961822,  0.18504953],\n",
              "       [-0.07000327,  0.16449781, -0.09449454]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# TODO: Gradients multiclasses\n",
        "def dJn(X: np.ndarray, H: np.ndarray, Y: np.ndarray) -> np.ndarray:\n",
        "    M = Y.shape[0]\n",
        "    return 1/M*X.T @ (H-Y)\n",
        "\n",
        "#=====================================================================\n",
        "# TEST UNITAIRE\n",
        "#=====================================================================\n",
        "# Resultat : \n",
        "# array([[-0.06543131, -0.11961822,  0.18504953],\n",
        "#        [-0.07000327,  0.16449781, -0.09449454]])\n",
        "#---------------------------------------------------------------------\n",
        "X_tn = np.array([[0., 0.], [1., 0.], [0., 1.], [1., 1.]])\n",
        "H_tn = np.array([[0.33333333, 0.33333333, 0.33333333],\n",
        "                 [0.36029662, 0.24151404, 0.39818934],\n",
        "                 [0.34200877, 0.37797814, 0.28001309],\n",
        "                 [0.37797814, 0.28001309, 0.34200877]])\n",
        "Y_tn = np.array([[1,0,0], [0,1,0], [0,0,1], [1,0,0]])\n",
        "\n",
        "dJn(X_tn, H_tn, Y_tn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL-gM5fC60Jd"
      },
      "source": [
        "### I.6. Descente du gradient adaptative\n",
        "\n",
        "**Rien à programmer ici**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl785U9W60Jd"
      },
      "outputs": [],
      "source": [
        "def descente(X, Y, Theta, ITER=100, alpha=0.1):\n",
        "    couts = []\n",
        "\n",
        "    Theta = Theta.copy() # pour ne pas modifier Theta original\n",
        "    \n",
        "    for i in range(ITER): # Ici, la seule condition d'arrêt est le nombre des itérations\n",
        "        H = softmax(zfn(X, Theta))\n",
        "        couts.append(jn(H, Y))\n",
        "        Theta = Theta - alpha * dJn(X, H, Y)\n",
        "    \n",
        "    return Theta, couts\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdu6Ay-560Jd"
      },
      "source": [
        "### I.7. Regrouper les fonctions ensemble \n",
        "\n",
        "Pour bien gérer l'entraînement et la prédiction, les fonctions que nous avions implémentées sont regroupées dans une seul classe. \n",
        "L'intérêt : \n",
        "- Si nous appliquons la normalisation durant l'entraînement, nous devons l'appliquer aussi durant la prédiction. En plus, nous devons utiliser les mêmes paramètres (moyenne et écart-type)\n",
        "- Nous utilisons les thétas optimales lors de la prédicition.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHE_4GGm60Je",
        "outputId": "cff52070-6a52-4a59-a754-846f4d50956e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "def normaliser(X, mean=None, std=None): \n",
        "    if (mean is None) or (std is None): \n",
        "        mean = np.mean(X, axis=0)\n",
        "        std = np.std(X, axis=0)\n",
        "    X_norm = np.where(std==0, X, (X - mean)/std)\n",
        "    return X_norm, mean, std\n",
        "\n",
        "def preparer(X, norm=True, const=True, mean=None, std=None): \n",
        "    X_pre = X.copy()\n",
        "    if norm: \n",
        "        X_pre, mean, std = normaliser(X_pre,mean=mean, std=std)\n",
        "    if const:\n",
        "        X_pre = np.append(np.ones((X_pre.shape[0],1)), X_pre ,axis=1)\n",
        "    return X_pre, mean, std\n",
        "\n",
        "class MaxEnt(object):\n",
        "    \n",
        "    def __init__(self, norm=True, const=True): \n",
        "        self.norm = norm\n",
        "        self.const = const\n",
        "    \n",
        "    def entrainer(self, X, Y, max_iter=100, alpha=.01): \n",
        "        X_pre, self.mean, self.std = preparer(X, norm=self.norm, const=self.const)\n",
        "        Theta = np.zeros((X_pre.shape[1], Y.shape[1])) # Theta[N, L]\n",
        "        self.Theta, self.couts = descente(X_pre, Y, Theta, ITER=max_iter, alpha=alpha)\n",
        "        \n",
        "        \n",
        "    # La prédiction\n",
        "    # si prob=True elle rend un vecteur de probabilités\n",
        "    # sinon elle rend une vecteur de 1 et 0\n",
        "    def predire(self, X, prob=True):\n",
        "        X_pre, self.mean, self.std = preparer(X, norm=self.norm, const=self.const, mean=self.mean, std=self.std)\n",
        "        H = softmax(zfn(X_pre, self.Theta))\n",
        "        if prob:\n",
        "            return H\n",
        "        return cn(H)\n",
        "\n",
        "\n",
        "#=====================================================================\n",
        "# TEST UNITAIRE\n",
        "#=====================================================================\n",
        "# Resultat : \n",
        "# array([[1, 0, 0],\n",
        "#        [0, 1, 0],\n",
        "#        [0, 1, 0],\n",
        "#        [0, 0, 1]])\n",
        "#---------------------------------------------------------------------\n",
        "X_tn = np.array([[0., 0.], [1., 0.], [0., 1.], [1., 1.]]) # deux variables logiques\n",
        "Y_tn = np.array([[1,0,0], [0,1,0], [0,0,1], [1,0,0]]) # égale, sup, inf, égale\n",
        "\n",
        "X_testn = np.array([[2., 2.], [1., 0.], [1., -1.], [2., 5.]])\n",
        "\n",
        "maxent = MaxEnt()\n",
        "maxent.entrainer(X_tn, Y_tn)\n",
        "maxent.predire(X_testn, prob=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGgiBzNx60Jf"
      },
      "source": [
        "## II. Application et analyse\n",
        "\n",
        "Nous allons utiliser [Iris dataset](https://archive.ics.uci.edu/ml/datasets/iris) pour classer des fleurs en trois classes, en utilisant 4 caractéristiques. \n",
        "Pour simplification, nous allons utiliser seulement 2 caractéristiques : Petal Length (cm); Petal Width (cm). \n",
        "D'après [Ce tutoriel](https://teddykoker.com/2019/06/multi-class-classification-with-logistic-regression-in-python/) ces deux caractéristiques sont suffisantes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsceR4SR60Jg",
        "outputId": "fd4ebf67-f11f-4a34-faa6-14f4ae730922"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width        class\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-549ebfdc-15dd-4bb0-b970-2a6a44d3de59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-549ebfdc-15dd-4bb0-b970-2a6a44d3de59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-549ebfdc-15dd-4bb0-b970-2a6a44d3de59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-549ebfdc-15dd-4bb0-b970-2a6a44d3de59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "iris = pd.read_csv('sample_data/iris.csv')\n",
        "iris.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z97GMkfB60Ji",
        "outputId": "9636c042-086d-4efe-c829-e2d88a7c12af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   petal_length  petal_width        class\n",
              "0           1.4          0.2  Iris-setosa\n",
              "1           1.4          0.2  Iris-setosa\n",
              "2           1.3          0.2  Iris-setosa\n",
              "3           1.5          0.2  Iris-setosa\n",
              "4           1.4          0.2  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5644a2ba-3d44-4a67-9cef-62d7d2becd4c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5644a2ba-3d44-4a67-9cef-62d7d2becd4c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5644a2ba-3d44-4a67-9cef-62d7d2becd4c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5644a2ba-3d44-4a67-9cef-62d7d2becd4c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "if iris.shape[1] > 3:\n",
        "    iris.drop(['sepal_length', 'sepal_width'], axis = 1, inplace=True)\n",
        "iris.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PLHohAz-60Ji",
        "outputId": "60e3c3c9-340d-4781-b639-80f2b9e06eee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    age  height_cm  weight_kg  body fat_%  diastolic  systolic  gripForce  \\\n",
              "0  27.0      172.3      75.24        21.3       80.0     130.0       54.9   \n",
              "1  25.0      165.0      55.80        15.7       77.0     126.0       36.4   \n",
              "2  31.0      179.6      78.00        20.1       92.0     152.0       44.8   \n",
              "3  32.0      174.5      71.10        18.4       76.0     147.0       41.4   \n",
              "4  28.0      173.8      67.70        17.1       70.0     127.0       43.5   \n",
              "\n",
              "   sit and bend forward_cm  sit-ups counts  broad jump_cm class  \n",
              "0                     18.4            60.0          217.0     C  \n",
              "1                     16.3            53.0          229.0     A  \n",
              "2                     12.0            49.0          181.0     C  \n",
              "3                     15.2            53.0          219.0     B  \n",
              "4                     27.1            45.0          217.0     B  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17e55a60-a768-4c3a-adae-14b2dbd16ce2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>height_cm</th>\n",
              "      <th>weight_kg</th>\n",
              "      <th>body fat_%</th>\n",
              "      <th>diastolic</th>\n",
              "      <th>systolic</th>\n",
              "      <th>gripForce</th>\n",
              "      <th>sit and bend forward_cm</th>\n",
              "      <th>sit-ups counts</th>\n",
              "      <th>broad jump_cm</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27.0</td>\n",
              "      <td>172.3</td>\n",
              "      <td>75.24</td>\n",
              "      <td>21.3</td>\n",
              "      <td>80.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>54.9</td>\n",
              "      <td>18.4</td>\n",
              "      <td>60.0</td>\n",
              "      <td>217.0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>55.80</td>\n",
              "      <td>15.7</td>\n",
              "      <td>77.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>36.4</td>\n",
              "      <td>16.3</td>\n",
              "      <td>53.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31.0</td>\n",
              "      <td>179.6</td>\n",
              "      <td>78.00</td>\n",
              "      <td>20.1</td>\n",
              "      <td>92.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>44.8</td>\n",
              "      <td>12.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>181.0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32.0</td>\n",
              "      <td>174.5</td>\n",
              "      <td>71.10</td>\n",
              "      <td>18.4</td>\n",
              "      <td>76.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>41.4</td>\n",
              "      <td>15.2</td>\n",
              "      <td>53.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28.0</td>\n",
              "      <td>173.8</td>\n",
              "      <td>67.70</td>\n",
              "      <td>17.1</td>\n",
              "      <td>70.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>43.5</td>\n",
              "      <td>27.1</td>\n",
              "      <td>45.0</td>\n",
              "      <td>217.0</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17e55a60-a768-4c3a-adae-14b2dbd16ce2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17e55a60-a768-4c3a-adae-14b2dbd16ce2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17e55a60-a768-4c3a-adae-14b2dbd16ce2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# https://www.kaggle.com/datasets/kukuroo3/body-performance-data\n",
        "body = pd.read_csv('sample_data/bodyPerformance.csv')\n",
        "\n",
        "# transformer le sex en un vecteur de deux elements et supprimer le\n",
        "gender = OneHotEncoder().fit_transform(body[['gender']]).toarray()\n",
        "body.drop(['gender'], axis=1, inplace=True)\n",
        "body.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUZZiZaz60Jj",
        "outputId": "7c9477a2-db60-49ae-9fb0-5281221ecebb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-89f5e934b10e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mXbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;31m# Premières colonnes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Ajouter le sex encodé aux caractéristiques\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'body' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xbody = body.iloc[:, :-1].values # Premières colonnes \n",
        "\n",
        "# Ajouter le sex encodé aux caractéristiques\n",
        "Xbody = np.concatenate((Xbody, gender), axis=1)\n",
        "\n",
        "Ybody = body.iloc[:,  -1].values # Dernière colonne   \n",
        "\n",
        "Xbody_train, Xbody_test, Ybody_train, Ybody_test = train_test_split(Xbody, Ybody, \n",
        "                                                                    test_size   =0.2, # 20% pour le teste\n",
        "                                                                    random_state=0, \n",
        "                                                                    stratify    =Ybody) # stratification sur Yiris\n",
        "\n",
        "\n",
        "Xbody_train.shape, Xbody_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJatojly60Jj"
      },
      "source": [
        "### II.1. Séparabilité des classes\n",
        "\n",
        "Ici, nous allons vérifier la séparabilité des classes visuellement (en se basant sur les deux caractéristiques)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "zQlKFD-t60Jk",
        "outputId": "707a16fb-fb3b-4097-d6d8-9bc9d0e8f980"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "Xiris = iris.iloc[:, :-1].values # Premières colonnes \n",
        "\n",
        "Yiris = iris.iloc[:,  -1].values # Dernière colonne \n",
        "\n",
        "setosa     = iris['class'] == 'Iris-setosa'\n",
        "versicolor = iris['class'] == 'Iris-versicolor'\n",
        "virginica  = iris['class'] == 'Iris-virginica'\n",
        "\n",
        "plt.scatter(Xiris[setosa,     0], Xiris[setosa,     1], color='red'  , marker='o', label='Iris-setosa'    )\n",
        "plt.scatter(Xiris[versicolor, 0], Xiris[versicolor, 1], color='blue' , marker='v', label='Iris-versicolor')\n",
        "plt.scatter(Xiris[virginica,  0], Xiris[virginica,  1], color='green', marker='*', label='Iris-virginica' )\n",
        "\n",
        "plt.xlabel('sepal_length')\n",
        "plt.ylabel('sepal_width' )\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy5kVllH60Jk"
      },
      "source": [
        "**TODO : Analyser les résultats**\n",
        "- Que remarquez-vous concernant la séparabilité des 3 classes?\n",
        "- Donner une hypothèse concernant la performance d'un modèle de classement comme la régression logistique sur ce dataset (Rappel, Précision)\n",
        "- Justifier cette hypothèse (Rappel, Précision) en comparant les 3 classes\n",
        "\n",
        "**Réponse**\n",
        "- La  classe iris-setosa est facilement séparable des deux autres, mais il faudra un peu plus d'entrainement pour le modèle afin de séparer les classes iris-virginica et iris-versicolor car ces dernières se chevauchent\n",
        "\n",
        "- L'application de la regression logistique est en mesure d'obtenir une précision et un rappel élevés car le dataset forme un ensemble de données relativement simple qui contient trois classes équillibrés chacunes ayant des caractéristiques distinctes (peux de chevauchement) par example pour la classe iris-setosa on peut atteindre un rappel et une précision =1\n",
        "\n",
        "- Vue que les différentes classes sont relativement distinctes, il est probable que le modèle de régression logistique soit capable de bien distinguer entre les différentes classes et donc de produire des résultats de classification précis. Par conséquent, il est raisonnable de s'attendre à ce que la précision du modèle soit élevée .d'autre part, comme le dataset iris est équilibré, cela signifie que le nombre d'exemples dans chaque classe est à peu près le même. Par conséquent, le modèle sera entraîné sur un nombre égal d'exemples de chaque classe, ce qui devrait aider à minimiser les biais de classe dans les prédictions du modèle , car chaque classe est traitée de manière équivalente pendant l'entraînement.Cela signifie que le rappel du modèle, qui mesure la proportion de vrais positifs (i.e. la capacité à identifier correctement une classe donnée) devrait également être élevé."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w8cFeh960Jl",
        "outputId": "6f83f0ce-9a16-4688-946b-e94149ea6059"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120,\n",
              " 30,\n",
              " (array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object),\n",
              "  array([10, 10, 10])))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split  \n",
        "\n",
        "Xiris_train, Xiris_test, Yiris_train, Yiris_test = train_test_split(Xiris, Yiris, \n",
        "                                                                    test_size   =0.2, # 20% pour le teste\n",
        "                                                                    random_state=0, \n",
        "                                                                    stratify    =Yiris) # stratification sur Yiris\n",
        "\n",
        "len(Xiris_train), len(Xiris_test), np.unique(Yiris_test, return_counts=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEn8fwuR60Jm"
      },
      "source": [
        "### II.2. One-vs-Rest OU MaxEnt\n",
        "\n",
        "Nous avons entrainé deux modèles : \n",
        "1. **One-vs-Rest** : ici, trois sous-modèles binaires sont entraînés ; un pour chaque class. Chaque sous modèle détecte si l'échantillon appartient à sa classe ou non. Lors de la prédiction, on prend la classe avec le max de probabilité\n",
        "1. **MaxEnt** : ici, un modèle de régression logistique multinomiale (maximum entropy) est entraîné pour séparer les trois classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6EA5vEu60Jm",
        "outputId": "53392e22-dc6e-4d85-cdd2-2472efb24220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-Rest\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00        10\n",
            "Iris-versicolor       0.91      1.00      0.95        10\n",
            " Iris-virginica       1.00      0.90      0.95        10\n",
            "\n",
            "       accuracy                           0.97        30\n",
            "      macro avg       0.97      0.97      0.97        30\n",
            "   weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "MaxEnt\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00        10\n",
            "Iris-versicolor       1.00      1.00      1.00        10\n",
            " Iris-virginica       1.00      1.00      1.00        10\n",
            "\n",
            "       accuracy                           1.00        30\n",
            "      macro avg       1.00      1.00      1.00        30\n",
            "   weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "one2rest = LogisticRegression(solver='lbfgs', penalty=None, multi_class='ovr'        )\n",
        "one2one  = LogisticRegression(solver='lbfgs', penalty=None, multi_class='multinomial')\n",
        "\n",
        "one2rest.fit(Xiris_train, Yiris_train)\n",
        "one2one .fit(Xiris_train, Yiris_train)\n",
        "\n",
        "print('One-vs-Rest')\n",
        "print(classification_report(Yiris_test, one2rest.predict(Xiris_test)))\n",
        "\n",
        "print('MaxEnt')\n",
        "print(classification_report(Yiris_test, one2one.predict(Xiris_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3R2tlxP60Jn"
      },
      "source": [
        "**TODO : Analyser les résultats**\n",
        "\n",
        "Nous remarquons que la performance de MaxEnt est meilleure que celle de One-vs-Rest\n",
        "- Pourquoi ? (en se basant sur la limite de décision et les paramètres)\n",
        "- Quelle est l'approche (parmi ces deux) qui est affectée beaucoup plus par les valeurs aberrantes (les échantillons d'une classe qui peuvent se retrouver aux milieu d'une autre classe)\n",
        "\n",
        "**Réponse**\n",
        "-  Maximum Entropy (MaxEnt) est plus robuste que OvR car il est moins sensible aux échantillons qui se trouvent près de la frontière de décision (valeurs aberantes). La raison en est que MaxEntropy prend en compte les différentes classes simultanément lors de la classification, ce qui permet de mieux prendre en compte les relations entre elles et d'améliorer la précision de la classification. Alors que dans l'approche OvR, chaque classe est comparée à toutes les autres classes de manière indépendante, ce qui peut entraîner des conflits et des ambiguïtés dans la classification.\n",
        "\n",
        "- l'approche qui est affecté le plus par les valeurs aberrantes est OvR ,cela est du au fait qu'il traite chaque classe séparément en utilisant des modèles de classification binaires,Par exemple, supposons que nous ayons trois classes : A, B et C. Dans l'approche OvR, nous construisons trois classificateurs binaires : A vs (B+C), B vs (A+C) et C vs (A+B). Si une instance est proche de la frontière entre la classe A et la classe B, elle peut être classée à tort comme appartenant à la classe C, car les classificateurs pour A vs (B+C) et B vs (A+C) peuvent tous les deux avoir des scores faibles pour cette instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTj6fhgn60Jn"
      },
      "source": [
        "### II.3. One-vs-Rest OU One-vs-One\n",
        "\n",
        "Nous avons entrainé deux modèles : \n",
        "1. One-vs-Rest\n",
        "1. One-vs-One\n",
        "\n",
        "Les deux modèles sont comparés en se basant sur plusieurs critères."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhlgLMq860Jo"
      },
      "outputs": [],
      "source": [
        "# https://goshippo.com/blog/measure-real-size-any-python-object/\n",
        "import sys\n",
        "\n",
        "def get_size(obj, seen=None):\n",
        "    \"\"\"Recursively finds size of objects\"\"\"\n",
        "    size = sys.getsizeof(obj)\n",
        "    if seen is None:\n",
        "        seen = set()\n",
        "    obj_id = id(obj)\n",
        "    if obj_id in seen:\n",
        "        return 0\n",
        "    # Important mark as seen *before* entering recursion to gracefully handle\n",
        "    # self-referential objects\n",
        "    seen.add(obj_id)\n",
        "    if isinstance(obj, dict):\n",
        "        size += sum([get_size(v, seen) for v in obj.values()])\n",
        "        size += sum([get_size(k, seen) for k in obj.keys()])\n",
        "    elif hasattr(obj, '__dict__'):\n",
        "        size += get_size(obj.__dict__, seen)\n",
        "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
        "        size += sum([get_size(i, seen) for i in obj])\n",
        "    return size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvqCkUXC60Jo",
        "outputId": "6533b9cd-68b9-40a3-f103-0481e37bf37d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-05bb70073303>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtemps_debut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0movr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXbody_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYbody_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mtemps_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtemps_debut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Xbody_train' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
        "import sys, timeit\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ce block du code est pour filtrer les avertissements concernant la convergence du modèle\n",
        "# en général, lorsque e nombre des itérations n'est pas suffisant pour atteindre l'erreur minimale\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
        "\n",
        "ovr = OneVsRestClassifier(LogisticRegression(solver='lbfgs', max_iter=100, penalty=None, n_jobs=1))\n",
        "ovo = OneVsOneClassifier (LogisticRegression(solver='lbfgs', max_iter=100, penalty=None, n_jobs=1))\n",
        "\n",
        "temps_train = []\n",
        "\n",
        "temps_debut = timeit.default_timer()\n",
        "ovr.fit(Xbody_train, Ybody_train)\n",
        "temps_train.append(timeit.default_timer() - temps_debut)\n",
        "\n",
        "temps_debut = timeit.default_timer()\n",
        "ovo.fit(Xbody_train, Ybody_train)\n",
        "temps_train.append(timeit.default_timer() - temps_debut)\n",
        "\n",
        "temps_test = []\n",
        "\n",
        "temps_debut = timeit.default_timer()\n",
        "ovr_res = ovr.predict(Xbody_test)\n",
        "temps_test.append(timeit.default_timer() - temps_debut)\n",
        "\n",
        "temps_debut = timeit.default_timer()\n",
        "ovo_res = ovo.predict(Xbody_test)\n",
        "temps_test.append(timeit.default_timer() - temps_debut)\n",
        "\n",
        "taille = [get_size(ovr), get_size(ovo)]\n",
        "\n",
        "accuracy = [\n",
        "    accuracy_score(Ybody_test, ovr_res),\n",
        "    accuracy_score(Ybody_test, ovo_res)\n",
        "]\n",
        "\n",
        "\n",
        "pd.DataFrame({\n",
        "    'Algorithme'            : ['OvR', 'OvO']  ,\n",
        "    'Taille'                : taille,\n",
        "    'Temps d\\'entrainement' : temps_train,\n",
        "    'Temps de test'         : temps_test,\n",
        "    'Accuracy'              : accuracy,\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-erSJC-h60Jp"
      },
      "source": [
        "**TODO : Analyser les résultats**\n",
        "\n",
        "- Pourquoi la taille OvO est plus grande que celle de OvR ?\n",
        "- Le temps d'entrainement est différent d'une exécution à une autre. Quand est-ce que un modèle est plus rapide que l'autre ?\n",
        "- Par contre, le temps de test OvO est plus lourd. Pourquoi?\n",
        "- Si nous pouvons paralleliser tous les modèles binaires, quel est l'effet sur les deux ?\n",
        "- Pourquoi OvO généralise-t-il mieux que OvR ?\n",
        "- Pouvons-nous utiliser OvR pour multi-label ? Pourquoi ?\n",
        "- Pouvons-nous utiliser OvO pour multi-label ? Pourquoi ?\n",
        "\n",
        "**Réponse**\n",
        "- La taille de OvO est plus grande que OvR car OVO nécessite la formation de N(N-1)/2 modèles binaires pour N classes, tandis que OVR nécessite la formation de N modèles binaires. Ainsi, OVO est plus coûteux en termes de temps et de **mémoire** (pour stocker les paramètres du modèle) que OVR.\n",
        "\n",
        "- Lorsque le nombre de classes est élevé, le nombre de classificateurs binaires requis pour OvO peut devenir très grand, ce qui peut augmenter le temps de calcul et la mémoire nécessaires pour stocker les paramètres de modèle. Dans ce cas, OvR peut être plus rapide et plus efficace car il ne nécessite que k classificateurs binaires.Cependant, lorsque le nombre de classes est relativement petit, le nombre de classificateurs binaires requis pour OvO est plus faible et peut être plus rapide et plus efficace que OvR. En effet, avec OvO, les classificateurs binaires ne sont entraînés que sur des sous-ensembles de données contenant deux classes, ce qui peut être plus rapide que l'entraînement de k classificateurs binaires pour OvR ou chaque classificateur binaire est entraîné sur tout l'ensemble de données.\n",
        "\n",
        "- Le temps de test pour OvO est plus lourd que pour OvR en raison du nombre de classificateurs binaires nécessaires pour OvO. Avec OvO, un classificateur binaire est entraîné pour chaque paire de classes distinctes, ce qui signifie que le nombre total de classificateurs binaires requis est de (K*(K-1))/2, où K est le nombre de classes. Par conséquent, si le nombre de classes est élevé, le nombre de classificateurs binaires requis pour OvO peut devenir très grand, ce qui peut augmenter le temps de prédiction lors du test.Avec OvO, chaque instance de test doit être évaluée par tous les classificateurs binaires, puis le vote majoritaire est utilisé pour déterminer la classe finale. Par conséquent, si le nombre de classes est très grand, le temps de test peut devenir très coûteux en termes de temps de calcul et de ressources nécessaires.\n",
        "En revanche, avec l'approche OvR, chaque instance de test est évaluée par un seul classificateur binaire créé lors de l'entraînement. Ainsi, le temps de test est généralement plus rapide que pour l'approche OvO, même si le nombre de classificateurs binaires créés peut être plus élevé.\n",
        "\n",
        "- Avec OvO, chaque classificateur binaire travaille sur un sous-ensemble de données contenant deux classes, de sorte que chaque classificateur binaire peut être entraîné indépendamment des autres. Si nous pouvons paralléliser l'entraînement de tous les classificateurs binaires, cela peut accélérer considérablement le temps d'entraînement de l'ensemble du modèle.\n",
        "De même, avec OvR, chaque classificateur binaire travaille sur toutes les données à l'exception d'une seule classe. Si nous pouvons paralléliser l'entraînement de chaque classificateur binaire, cela peut également accélérer le temps d'entraînement de l'ensemble du modèle.\n",
        "En résumé, si nous pouvons paralléliser l'entraînement des classificateurs binaires, cela peut accélérer le temps d'entraînement de l'ensemble du modèle pour les deux approches de classification, mais le choix entre OvO et OvR dépendra toujours du nombre de classes et de la taille des données.\n",
        "Cependant, même si nous pouvons paralléliser l'entraînement des classificateurs binaires, le nombre de classificateurs binaires requis pour OvO peut encore être très grand si le nombre de classes est élevé. Dans ce cas, OvR peut toujours être plus efficace en termes de temps d'entraînement et de mémoire requise pour stocker les paramètres du modèle.\n",
        "\n",
        "- L'une des raisons pour lesquelles OvO peut généraliser mieux est qu'il réduit le risque de surajustement (overfitting) par rapport à OvR. En effet, avec OvO, chaque classificateur binaire est entraîné sur un sous-ensemble de données contenant seulement deux classes, ce qui peut être bénéfique lorsque le nombre de classes est élevé et les données sont très hétérogènes. Cela peut permettre aux classificateurs binaires d'être plus adaptés aux caractéristiques spécifiques de chaque paire de classes, plutôt que de créer un seul classificateur pour toutes les classes.\n",
        "En outre, l'approche OvO peut également aider à améliorer la précision globale du modèle, car elle utilise le vote majoritaire pour déterminer la classe finale. Cela peut aider à compenser les erreurs de classification individuelles des classificateurs binaires et améliorer la performance globale du modèle.\n",
        "\n",
        "- oui,La classification multilabel consiste à entraîner un classificateur binaire pour chaque étiquette en considérant cette étiquette par rapport à toutes les autres étiquettes combinées ,mais la méthode OvR suppose que les étiquettes sont indépendantes les unes des autres, ce qui peut ne pas être vrai pour tous les problèmes de classification multi-étiquettes. Dans les cas où les étiquettes sont fortement corrélées cela peut conduire à une performance médiocre.\n",
        "\n",
        "- Oui, on pourrait construire plusieurs classificateurs indépendants et ensuite choisir la classe pour laquelle la confiance est maximisée.\n",
        "cela revient à évaluer l'appartenance de l'instance a plusieurs classes différentes (multilabel)\n",
        "\n",
        "- Non ,Dans la classification multi-label un exemple peut appartenir à plus d'une classe, l'utilisation de la méthode OvO peut devenir coûteuse en termes de calcul et nécessiter l'apprentissage d'un grand nombre de classificateurs, en particulier s'il y a beaucoup de classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQgDXR_260Jp",
        "outputId": "5a02e823-219d-4b4c-af4e-a0666612b1e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'FIN du TP ... Enfin! :)'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'FIN du TP ... Enfin! :)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtlOM4U860Jq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}